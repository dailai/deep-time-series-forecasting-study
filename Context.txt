目录:
1. 熟悉pandas.Series 的时序数据操作
2.1
一直一来，我们都是用 TensorFlow 框架搭建深度神经网络，但其实 python
也提供了相应的统计和学习模块，比如我们要拟合函数 y = x**2
2.1.1
首先生成数据集 x 和标准数据 y = x **2
4. 第4章 模型中加入其它特征(Additional Attributes)
5.
第5章 循环神经网络入门
5.1 循环神经网络(RNN)的示意图(演示200秒)
5.2 Keras, TensorFlow, Theano 的关系
5.3 运行一个 RNN 模型
5.3.1 如前面演示学习中所述, RNN 网络中的第 l+1 层(显式地)记忆了第 l 层 的隐藏层信息, 同时第 l 层的输出又是根据第 l 层的隐藏层通过
权重学习, 然后被非线性激活函数处理后得到的结果, 因此我们可以理解为: 后一层的计算使用了前一层的输出, 如此循环下去, 最终构成了循环神经网络
5.3.2 获取 coe 数据 含有列: DATE,COE$,COE$_1,#Bids,Quota,Open?
5.3.3 生成训练数据(95%)与测试数据(5%)
5.3.4 引入 Keras 模块

          from keras.models import Sequential  # 目的: 可以做linear stacking of layers
          from keras.optimizers import SGD  # 目的: 随机梯度下降
          from keras.layers.core import Dense, Activation  # 目的: 引入激活函数以及一个全连接层(output 层)
          from keras.layers.recurrent import SimpleRNN  # 目的: 引入一个将输出喂给输入的全连接循环神经网络
     全连接层的含义: 全连接层中的每个神经元与其前一层的所有神经元进行全连接
5.3.5 确定模型参数

          rnn5 = Sequential() # 目的: 确定后面可以通过 add 方法来增加网络中的层
          rnn5.add(
              SimpleRNN(output_dim=8, activation="tanh", input_shape=(4, 1))
          )
          # 目的: 构造8层循环, 激活函数为tanh函数(取值介于(-1,1)), 输入含4个特征维度, 时间步长为1.
          rnn5.add(
              Dense(output_dim=1, activation="linear")
          )
          # 目的: 增加1个全输出连接层, 激活函数使用线性函数
    5.3.6 使用 momentum
学习速率与momentum配合使用是一种技巧, 谁用谁知道.
 momentum 示意图(演示40秒)
5.3.7 选择 momentum(动量), 并在 Netsterov 梯度加速下降方法使用
5.3.7.1 Netsterov 梯度加速下降(1阶优化方法, 提高稳定性与速度(Newton 法是几阶?)) 示意图(演示40秒)
5.3.7.2 Netsterov 与 momentum 调用方式

          sgd = SGD(lr=0.0001, momentum=0.95,nesterov=True)
          rnn5.compile(loss="mean_squared_error", optimizer=sgd)
5.3.8 现在我们还要使用 Mini Batch
一个epoch遍历一次数据, 为了完成这个epoch, 我们可以选择全部训练样本数据去做计算更新一步参数(很多),
 也可以只用一个(随机梯度默认就会这样子做了), 我们还可以把一个epoch的数据分成很多个mini batch,
 一个mini batch(如 batch_size=10)可以用来更新一次参数, 然后迭代多次来完成这个epoch.
5.3.9 模型训练 fit
5.3.9.1 调用rnn5.fit()
5.3.9.2 查看训练测试(预测)的误差
5.3.10 获取预测数据并还原成原尺度
作图:显示部分历史时间数据
6.
第6章 循环神经网络进阶: Elman Neural Networks(含延滞层)
6.1 Elman NN广泛应用于控制, 优化, 模式分类
